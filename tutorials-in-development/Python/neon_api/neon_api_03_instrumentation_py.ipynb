{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "syncID: \n",
    "title: \"Introduction to NEON API in Python\"\n",
    "description: \"Use the NEON API in Python, via requests package and json package.\"\n",
    "dateCreated: 2020-04-24\n",
    "authors: Maxwell J. Burner\n",
    "contributors: Donal O'Leary\n",
    "estimatedTime:\n",
    "packagesLibraries: requests, json, pandas\n",
    "topics: api\n",
    "languagesTool: python\n",
    "dataProduct: DP1.00041.001\n",
    "code1: \n",
    "tutorialSeries: python-neon-api-series\n",
    "urlTitle: neon-api-03-instrumentation-data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn about reading in NEON instrument systems (IS) data using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"ds-objectives\" markdown=\"1\">\n",
    "\n",
    "### Objectives\n",
    "After completing this tutorial, you will be able to:\n",
    "\n",
    "* Understand naming conventions of NEON IS Data\n",
    "* Navigate NEON API data on availability of IS data product files\n",
    "* Download files with context for interpreting IS data\n",
    "* Download NEON IS data using the Python Pandas package\n",
    "\n",
    "### Install Python Packages\n",
    "\n",
    "* **requests**\n",
    "* **json** \n",
    "* **pandas**\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn how to download IS data from the NEON portal using Python. We will cover how to get necessary metadata and context, and how to download the data itself into Pandas dataframes.\n",
    "\n",
    "In the previous tutorial, we saw an example of how to download NEON data through the NEON API. Specifically, we saw how to query and download data from observational sampling, OS data, which is directly gathered by NEON field scientists. NEON also uses automated instruments, and thus has Instrument System Data or IS Data. IS Data tends to be stored in files with different naming and labeling formats compared to OS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Data Availability using NEON API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get soil temperature data from NEON's Woodworth site. Soil temperature data is measured and recorded automatically by soil temeprature probes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER = 'http://data.neonscience.org/api/v0/'\n",
    "SITECODE = 'WOOD'\n",
    "PRODUCTCODE = 'DP1.00041.001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get availability\n",
    "site_request = requests.get(SERVER+'sites/'+SITECODE)\n",
    "site_json = site_request.json()\n",
    "\n",
    "for product in site_json['data']['dataProducts']:\n",
    "    if(product['dataProductCode'] == PRODUCTCODE):\n",
    "        print(product['availableMonths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing as this dataset is collected by automated instruments, it is available (mostly continuously) since the site was established. Let's get the first 20 data file names available for August 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Request available files\n",
    "data_request = requests.get(SERVER+'data/'+PRODUCTCODE+'/'+SITECODE+'/'+'2018-08')\n",
    "data_json = data_request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in data_json['data']['files'][0:20]:\n",
    "    print(file['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the name of one of these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_json['data']['files'][7]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format for naming instrumentation data files, specifically soil temperature measurements, is:\n",
    "\n",
    "NEON.D[Domain Number].[site code].[data product ID].[soil plot number].[depth].[averaging interval].[data table name].[year]-[month].[data package type].[date of file creation].[file extension]\n",
    "\n",
    "So this is Domain 09, Woodworth, soil temperature IS data (DP1.00041.001), collected in plot 001, collected at depth [508] averaged over 30-minute intervals, data table 2018-08.basic, created 2019-03-20 at 15:35:55. Similarly to observational data packages, instrumentational data can be downloaded in a basic or expanded package; the data table 2018-08.basic is the basic data package for August 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Context\n",
    "\n",
    "Not all of the files listed in this request are CSV files with recorded data. Some store other information, in tables or in text, used to provide context to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View names of files that don't containg recoded sensor data\n",
    "for file in data_json['data']['files']:\n",
    "    if(not ('basic' in file['name'])):\n",
    "        if(not ('expanded' in file['name'])): #Avoid csv files of basic or expanded data\n",
    "            print(file['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files include \"read me\" text files, and files with descriptions of the variables being measured. These provide useful context in interpreting and using the data we download. First we take a quick look at the readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain url of text file and readme\n",
    "for file in data_json['data']['files']:\n",
    "    if('readme' in file['name']):\n",
    "        readme_url = file['url']\n",
    "    elif('variables' in file['name']):\n",
    "        variable_url = file['url']\n",
    "        \n",
    "readme_req = requests.get(readme_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print contents of text file\n",
    "print(readme_req.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at the 'variables' CSV file listed above. As with observational data products, this contains a table with a row for every variable in the basic and expanded data CSVs, and columns containing various information about each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read variables csv into pandas dataframe\n",
    "df_variables = pd.read_csv(variable_url)\n",
    "\n",
    "\n",
    "#Filter and show rows for variables in a 1-minute-average table and basic download package\n",
    "df_variables[(df_variables['table'] == 'ST_1_minute')&(df_variables['downloadPkg'] == 'basic')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Instrument Data\n",
    "\n",
    "Now that we have context for each variable, let's read in a CSV file for 1-minute-average soil temperature at WOOD in August 2018. We will again use the Pandas library to enable the use of dataframe objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check file name and read in file to a data frame\n",
    "print(data_json['data']['files'][6]['name'])\n",
    "df_soil_1min = pd.read_csv(data_json['data']['files'][6]['url'])\n",
    "\n",
    "#Display dimensions:\n",
    "print('Number of columns: ',df_soil_1min.shape[1])\n",
    "print('Number of rows: ', df_soil_1min.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display names and types of columns\n",
    "df_soil_1min.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many of the values are \"aggregation\" sample statistics, like mean, minimum, maximum, etc. This indicates that we aren't getting every single recorded soil temperature; as the table name suggests, we are getting the summary statistics for the data, aggregated over periods of one minute. So the first row includes mean, minimum, and maximum soil temperature for the first minute recording took place (specified by the start and end date-time variables), the second row includes a summary of values for the second minute recording took place, and so forth. Uploading different files from the available data could provide data aggregated over different time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print first ten rows of data\n",
    "df_soil_1min.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manipulate the data using Pandas and other Python libraries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
